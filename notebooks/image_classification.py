# -*- coding: utf-8 -*-
"""Image_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qiPEeHSTsHDvNnPh35In-useY6dpueh-
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install keras-tuner
# !pip install lime

import os
import random
import shutil
import pathlib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

## Libraries for Image Processing
import tensorflow as tf
import cv2
import imghdr
import os
import keras_tuner as kt

# from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef, roc_auc_score
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input
from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy
from hyperopt import hp, fmin, tpe
from keras.applications.vgg16 import VGG16
from keras.models import Model
from sklearn.model_selection import GridSearchCV
from keras.models import load_model

# import lime
from lime import lime_image
from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt
import random

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""# **Data Loading and Exploration**"""

class_labels = ["Class_0", "Class_1"]
dataset_folder_name = "/content/drive/MyDrive/IS4242 Project/self_collected_Data"
train_path = os.path.join(dataset_folder_name, 'Train')
validation_path = os.path.join(dataset_folder_name, 'Validation')
test_path = os.path.join(dataset_folder_name, 'Test')
random.seed(0)

data = tf.keras.utils.image_dataset_from_directory(train_path)

# Checking for unsupported images
import PIL
from pathlib import Path
from PIL import UnidentifiedImageError

path = Path(train_path).rglob("*.png")
for img_p in path:
    try:
        img = PIL.Image.open(img_p)
    except PIL.UnidentifiedImageError:
            print(img_p)

# Show random data sample where Class 0 is not suspicious and Class 1 is suspicious
data_iterator = data.as_numpy_iterator()
batch = data_iterator.next()
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch[1][idx])

# show data distribution in both classes - seems relatively even
classes = {'Class_0': "Not Suspicious", 'Class_1':"Suspicious"}
train_number = []
class_num = []
folders = os.listdir(train_path)

for folder in folders:
    train_files = os.listdir(train_path + '/' + folder)
    train_number.append(len(train_files))
    class_num.append(classes[folder])

fig, ax = plt.subplots(figsize=(8, 6))
barchart = sns.barplot(x=class_num, y=train_number, ax=ax)
barchart.bar_label(ax.containers[0], label_type='edge', padding=3)

class_1_folders = os.listdir(train_path + '/Class_1')

sub_category = {"device":0 , "positioning":0, "someone":0, "background":0, "combined":0}
for file in class_1_folders:
  file_name = file.replace(".png", "")
  sub_str= file_name[-2:]
  if sub_str == "00":
    sub_category["device"] += 1
  elif sub_str == "01":
    sub_category["positioning"] += 1
  elif sub_str == "02":
    sub_category["someone"] += 1
  elif sub_str == "03":
    sub_category["background"] += 1
  else:
    sub_category["combined"] += 1

names = list(sub_category.keys())
values = list(sub_category.values())
fig, ax = plt.subplots(figsize=(8, 6))
barchart = sns.barplot(x=names, y=values, ax=ax)
barchart.bar_label(ax.containers[0], label_type='edge', padding=3)

""" ### Data Augmentation to Deploy"""

# show samples of original image from two classes
images = ['/Class_0/00_0001.png', '/Class_1/01_0001_00.png']

plt.figure(figsize=(10,8))
for index, image_relative_path in enumerate(images):
  image_path = train_path + image_relative_path
  img = load_img(image_path, target_size= (500,500))
  img_tensor = img_to_array(img)
  img_tensor = np.expand_dims(img_tensor, axis=0)
  # Rescaling values in array for proper visualisation of images
  img_tensor /= 255.
  # Plot a sample image from both classes
  plt.subplot(1, 2, index+1)
  plt.imshow(img_tensor[0])
plt.show()

# Uses ImageDataGenerator to perform horizontal flip of the images
image_path = train_path + '/Class_0/00_0001.png'
img = load_img(image_path, target_size= (500,500))
img_tensor = img_to_array(img)
img_tensor = np.expand_dims(img_tensor, axis=0)

def plot_image(datagen):
  # Creates the batch of one image
  pic = datagen.flow(img_tensor, batch_size =1)
  plt.figure(figsize=(10,8))
  for i in range(1,4):
    plt.subplot(1, 3, i)
    batch = pic.next()
    image_ = batch[0].astype('uint8')
    plt.imshow(image_)
  plt.show()

datagen = ImageDataGenerator(horizontal_flip=True)
plot_image(datagen)

datagen = ImageDataGenerator(rotation_range=10)
plot_image(datagen)

datagen = ImageDataGenerator(height_shift_range=[0.1, 0.15])
plot_image(datagen)

datagen = ImageDataGenerator(brightness_range=[0.5, 1.5])
plot_image(datagen)

"""# **Define Common Functions**

### Functions for Image File Movement
"""

def move_between_folders(source, destination, ratio):
    '''
    This is a helper function to move images from source to destination folder with given ratio.
    '''
    source_files = os.listdir(source)
    if(len(source_files) != 0):
        # get number of files to transfer based on the given ratio then randomly select the index to decide the images to transfer
        num_of_transfer_file = int(len(source_files)*ratio)
        transfer_index = random.sample(range(0, len(source_files)), num_of_transfer_file) # random sampling of images
        for index in transfer_index:
            shutil.move(os.path.join(source, str(source_files[index])), os.path.join(destination, str(source_files[index])))

def move_all_labels_data_between_folders(source, destination, ratio):
    '''
    This is a helper function to move images from source to destination folder for both class labels.
    '''
    for label in class_labels:
        source_path = os.path.join(dataset_folder_name, source, label)
        destination_path = os.path.join(dataset_folder_name, destination, label)
        move_between_folders(source_path, destination_path, ratio)

def prepare_name_with_labels(folder_name, data_type, X, Y):
    '''
    This is a helper function to construct the X which are image files and Y which are class labels 0 and 1.
    '''
    source_files = os.listdir(os.path.join(dataset_folder_name, data_type, folder_name))
    y_label = 0
    for i in range(len(class_labels)):
        if(folder_name == class_labels[i]):
            y_label = i
    for image in source_files:
        X.append(image)
        Y.append(y_label)
    return X, Y

# Ensure at the initial phase, all images are in Train folder
move_all_labels_data_between_folders('Test', 'Train', 1.0)
move_all_labels_data_between_folders('Validation', 'Train', 1.0)

"""### Function for Image Augmentation"""

def data_augmentation_train_val(img_rows, img_cols, batch_size):
    '''
    This is a function to perform image augmentation for training data and standardisation for all data
    '''
    train_datagen = ImageDataGenerator(
      rescale=1./255, 
      rotation_range=10, 
      height_shift_range=0.1,  
      horizontal_flip=True,
      brightness_range=[0.5, 1.5],
      fill_mode="nearest"
    )
    validation_datagen = ImageDataGenerator(rescale=1./255)

    train_generator = train_datagen.flow_from_directory(
        train_path,
        target_size=(img_rows, img_cols),
        batch_size=batch_size,
        class_mode='categorical',
        subset='training',
        shuffle=True,
        seed=4242)

    validation_generator = validation_datagen.flow_from_directory(
        validation_path,
        target_size=(img_rows, img_cols),
        batch_size=batch_size,
        class_mode='categorical',  
        shuffle=False,
        seed=4242)
    return train_generator, validation_generator

def data_augmentation_test(img_rows, img_cols, batch_size):
    test_datagen = ImageDataGenerator(rescale=1./255)
    test_generator = test_datagen.flow_from_directory(
        test_path,
        target_size=(img_rows, img_cols),
        batch_size=batch_size,
        class_mode=None,
        shuffle=False,
        seed=4242)
    return test_generator

"""### Function for Performance Metrics"""

def evaluate_results(y_true, y_pred, print_result=True):
    '''
    This is a helper function that we will call to print basic results statistics.
    '''
    # Create confusion matrix of validation data
    perf_metric = dict()
    cm = confusion_matrix(y_true, y_pred)
    TN, FP, FN, TP = cm.ravel()

    # Evaluation Statistics
    perf_metric["Accuracy"] = accuracy_score(y_true, y_pred)
    perf_metric["Recall"] = recall_score(y_true, y_pred)
    perf_metric["Precision"] = precision_score(y_true, y_pred)
    perf_metric["F1"] = f1_score(y_true, y_pred)
    perf_metric["MCC"] = matthews_corrcoef(y_true, y_pred)
    perf_metric["F1_macro"] = f1_score(y_true, y_pred, average = "macro")
    perf_metric["ROC_AUC"] = roc_auc_score(y_true, y_pred)

    if print_result:
      # Print confusion matrix
      print("Confusion Matrix: \n", cm)
      print("TN: %s, FP: %s, FN: %s, TP: %s" %(TN, FP, FN, TP))
      print("\n")
      # Print evluation metrics
      for metric, val in perf_metric.items():
        print("{}: {}".format(metric, val))
      print("\n")
      print("\n")
    return perf_metric

def result_presentation(perf_metric_list):
  '''
  This is a helper function to combine results of all n folds from cross validation and get average performance metrics.
  '''
  results = []
  metrics = ["Accuracy", "Recall", "Precision", "MCC", "F1", "F1_macro", "ROC_AUC"]
  num_folds = len(perf_metric_list)
  for metric in metrics:
    metric_result = {}
    sum = 0
    metric_result["Metric"] = metric
    for index in range(num_folds):
      value = perf_metric_list[index][metric]
      metric_result["Fold_{}".format(index+1)] = value
      sum += value
    averge = sum/num_folds
    metric_result["Average"] = averge    
    results.append(metric_result)
  results_df = pd.DataFrame.from_dict(results)
  return results_df

"""### Functions for Cross Validation and Test Result Evaluation"""

def cross_validation_model_training(folds_num, img_rows, img_cols, batch_size, epoch, model):
    '''
    This is the function to perform model training with cross validation and evaluate model performance.
    '''
    skf = StratifiedKFold(n_splits=folds_num, shuffle=True)
    skf.get_n_splits(X, Y)
    fold_num = 0
    perf_metric_list = []
    for train_index, val_index in skf.split(X, Y):
        # First make sure all images are in train folder
        move_all_labels_data_between_folders('Validation', 'Train', 1.0)
        fold_num += 1
        print("Results for fold", fold_num)
        X_train, X_val = X[train_index], X[val_index]
        Y_train, Y_val = Y[train_index], Y[val_index]
    
        # Move validation images of this fold from train folder to the validation folder
        for each_index in range(len(X_val)):
            class_label = ''
            for i in range(len(class_labels)):
                if(Y_val[each_index] == i):
                    class_label = class_labels[i]
            # Then copy the validation images to the validation folder
            shutil.move(os.path.join(dataset_folder_name, 'Train', class_label, X_val[each_index]),
                        os.path.join(dataset_folder_name, 'Validation', class_label, X_val[each_index]))

        # Perform image processing such as augmentation and standardisation
        train_generator, validation_generator = data_augmentation_train_val(img_rows, img_cols, batch_size)
        
        # fit model and make prediction
        history = model.fit(train_generator, validation_data=validation_generator, epochs=epoch)
        predictions = model.predict(validation_generator, verbose=1)
        y_pred = np.argmax(predictions, axis=1)
        y_true = validation_generator.classes

        #plot training vs val loss
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('model loss')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['Train', 'Validation'], loc='upper left')
        plt.show()
        
        # evaluate validation performance
        print("***Performance on Validation data***")
        perf_metrics = evaluate_results(y_true, y_pred, print_result=True)
        perf_metric_list.append(perf_metrics)
    move_all_labels_data_between_folders('Validation', 'Train', 1.0)
    return perf_metric_list

def test_results(img_rows, img_cols, batch_size, model):
    '''
    This is the function to evaluate model performance on the unseen test data.
    '''
    print("Performance on Test Data")
    test_generator = data_augmentation_test(img_rows, img_cols, batch_size)
    predictions = model.predict(test_generator, verbose=1)
    y_pred = np.argmax(predictions, axis=1)
    y_true = test_generator.classes
    perf_metrics = evaluate_results(y_true, y_pred, print_result=True)
    return perf_metrics

"""# **Models Comparison**

## Train Test Split
"""

# Use train test split ratio of 0.2, this test data does not involve in model training and only use in final evaluation of model.
move_all_labels_data_between_folders('Train', 'Test', 0.20)

"""## **Self-Constructed CNN**

### Bayesian Optimisation - CNN
"""

class NN_Model(kt.HyperModel):

    def build(self, hp):
        model = Sequential()

        # Tune number of convolution and pooling layers
        for i in range(hp.Int('num_hidden_layer', 2, 3)):
            # Tune the padding and filters 
            hp_padding=hp.Choice('padding_'+ str(i), values=['valid', 'same'])
            hp_filters=hp.Choice('filters_'+ str(i), values=[16, 32, 64])
            if i == 0:
                model.add(Conv2D(hp_filters, (3, 3), padding=hp_padding, activation='relu', input_shape=(img_rows, img_cols, num_of_channels)))  
            else:
                model.add(Conv2D(hp_filters, (3, 3), padding=hp_padding, activation='relu'))
            model.add(MaxPooling2D((2, 2)))
            # Tune the dropout rate
            model.add(Dropout(hp.Choice('dropout_'+ str(i), values=[0.0, 0.1, 0.2])))

        model.add(Flatten())

        # Tune the number of hidden neurons in the dense layer
        hp_units = hp.Int('units', min_value=32, max_value=128, step=32)
        model.add(Dense(hp_units, activation='relu', kernel_initializer='he_uniform'))
        model.add(Dense(2, activation="sigmoid"))

        # Tune the learning rate and type of optimizer
        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])
        hp_optimizer=hp.Choice('Optimizer', values=['Adam', 'SGD'])

        if hp_optimizer == 'Adam':
            hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])
        elif hp_optimizer == 'SGD':
            hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])
            nesterov=True
            momentum=0.9
        model.compile(optimizer = hp_optimizer, loss='binary_crossentropy', metrics=METRICS)
        return model

    def fit(self, hp, model, epochs, callbacks):
        # Tune the batch size
        batch_size =hp.Int('batch-size', min_value=32, max_value=128, step=32)
        train_generator, validation_generator = data_augmentation_train_val(img_rows, img_cols, batch_size)
        return model.fit(
            train_generator,
            epochs=epochs,
            callbacks=callbacks,
            validation_data=validation_generator
        )

img_rows, img_cols = 100, 100
epoch_num = 30
num_of_channels = 3

# metrics to use in model training
METRICS = [
      tf.keras.metrics.BinaryAccuracy(name='accuracy'),
      tf.keras.metrics.Precision(name='precision'),
      tf.keras.metrics.Recall(name='recall'),
      tf.keras.metrics.AUC(name='auc'),
      tf.keras.metrics.AUC(name='prc', curve='PR')
]


early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_prc', 
    verbose=1,
    patience=5,
    mode='max',
    restore_best_weights=True)


tuner = kt.tuners.BayesianOptimization(
    NN_Model(),
    seed=4242,
    objective=kt.Objective("val_prc", direction="max"), #'val_loss',
    max_trials=20,
    directory='.',
    project_name='tuning_cnn'
)

# NOTE: This takes 7 hours to run, may consider to skip the running and results file from tuning has uploaded in our github as well
# Perform the tuning process.
move_all_labels_data_between_folders('Train', 'Validation', 0.20)
tuner.search(epochs=epoch_num, callbacks=[early_stopping])
move_all_labels_data_between_folders('Validation', 'Train', 1.0)

# Print the results of first best three tuning results
# Skip this line if not running the tuning above, tuned results were 
print(tuner.results_summary(3))

move_all_labels_data_between_folders('Validation', 'Train', 1.0)

"""### Cross Validation to Evaluate Best CNN Model"""

# Use best hyper-parameters obtained from the tuning process above to construct the final model
def fully_connected_cnn(img_rows, img_cols, num_of_channels):
  '''
  This is the function to construct the model architecture.
  '''
  model = Sequential()
  model.add(Conv2D(32, (3, 3), padding="valid", activation='relu', input_shape=(img_rows, img_cols, num_of_channels)))
  model.add(MaxPooling2D((2, 2)))
  model.add(Conv2D(16, (3, 3), padding="valid", activation='relu'))
  model.add(MaxPooling2D((2, 2)))
  model.add(Conv2D(16, (3, 3), padding="same", activation='relu'))
  model.add(MaxPooling2D((2, 2)))
  model.add(Flatten())
  model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))
  model.add(Dense(2, activation="softmax"))
  opt = tf.keras.optimizers.Adam(learning_rate=0.01)
  model.compile(optimizer = opt, loss='binary_crossentropy', metrics=METRICS)
  return model

model = fully_connected_cnn(img_rows, img_cols, num_of_channels)
model.summary()

folds_num = 3
batch_size = 32
# Organize file names and class labels in X and Y variables
X, Y = [], []
for i in range(len(class_labels)):
    X, Y = prepare_name_with_labels(class_labels[i], "Train", X, Y)
X = np.asarray(X)
Y = np.asarray(Y)

perf_metric_list = cross_validation_model_training(folds_num, img_rows, img_cols, batch_size, epoch_num, model)

# Evaluate model performance during training process with cross validation
result_df = result_presentation(perf_metric_list)
result_df

# Evaluate model performance on test data
perf_result = test_results(img_rows, img_cols, batch_size, model)

# Save the model
model.save("/content/drive/MyDrive/IS4242 Project/models/model_cnn.hdf5")

"""##**VGG-16** """

def fully_connected_vgg(img_rows, img_cols, num_of_channels):
  vgg = VGG16(input_shape=[img_rows, img_cols, num_of_channels], weights='imagenet', include_top=False)
  for layer in vgg.layers:
    layer.trainable = False
  x = Flatten()(vgg.output)
  prediction = Dense(2, activation='softmax')(x)  
  model = Model(inputs=vgg.input, outputs=prediction)
  return model

folds_num = 3
img_rows, img_cols = 224, 224
batch_size = 64
epoch = 10
num_of_channels = 3
number_of_class_labels = len(class_labels)

model_vgg16 = fully_connected_vgg(img_rows, img_cols, num_of_channels)
model_vgg16.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])
model_vgg16.summary()

# Organize file names and class labels in X and Y variables
X, Y = [], []
for i in range(len(class_labels)):
    X, Y = prepare_name_with_labels(class_labels[i], "Train", X, Y)
X = np.asarray(X)
Y = np.asarray(Y)

perf_metric_list = cross_validation_model_training(folds_num, img_rows, img_cols, batch_size, 20, model_vgg16)

result_df = result_presentation(perf_metric_list)
result_df

perf_result = test_results(img_rows, img_cols, batch_size, model_vgg16)

path = '/content/drive/MyDrive/IS4242 Project/models/model_vgg16.hdf5'
model_vgg16.save(path)

"""##**VGG19**"""

from keras.applications.vgg19 import VGG19

class MyHyperModel(kt.HyperModel):
    def build(self, hp):

        base_model=VGG19(
          include_top=False,
          weights="imagenet",
          input_shape=[img_rows, img_cols, num_of_channels])

        base_model.trainable = False
        model = Sequential()
        model.add(base_model)
        model.add(Flatten())
        model.add(Dense(2,activation='softmax')) 


        # Tune the learning rate and type of optimizer
        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])
        hp_optimizer=hp.Choice('Optimizer', values=['Adam', 'SGD'])

        if hp_optimizer == 'Adam':
            hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])
        elif hp_optimizer == 'SGD':
            hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])
            nesterov=True
            momentum=0.9
        model.compile(optimizer = hp_optimizer, loss='binary_crossentropy', metrics=["accuracy"])

        return model

    def fit(self, hp, model, epochs, callbacks):
        # Tune the batch size
        batch_size =hp.Int('batch-size', min_value=32, max_value=128, step=32)
        train_generator, validation_generator = data_augmentation_train_val(img_rows, img_cols, batch_size)
        return model.fit(
            train_generator,
            epochs=epochs,
            callbacks=callbacks,
            validation_data=validation_generator
        )

img_rows, img_cols = 224, 224
epoch_num = 30
num_of_channels = 3

# metrics to use in model training
METRICS = [
      tf.keras.metrics.BinaryAccuracy(name='accuracy'),
      tf.keras.metrics.Precision(name='precision'),
      tf.keras.metrics.Recall(name='recall'),
      tf.keras.metrics.AUC(name='auc'),
]


early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', 
    verbose=1,
    patience=5,
    mode='max',
    restore_best_weights=True)


tuner = kt.tuners.BayesianOptimization(
    MyHyperModel(),
    seed=4242,
    objective=kt.Objective("val_loss", direction="max"), #'val_loss',
    max_trials=10,
    directory='.',
    project_name='tuning_vgg'
)

move_all_labels_data_between_folders('Train', 'Validation', 0.20)
tuner.search(epochs=epoch_num, callbacks=[early_stopping])
move_all_labels_data_between_folders('Validation', 'Train', 1.0)

print(tuner.results_summary(1))

def vgg_19(img_rows, img_cols, num_of_channels):
  vgg_19_model = VGG19(input_shape=[img_rows, img_cols, num_of_channels], weights='imagenet', include_top=False)
  for layer in vgg_19_model.layers:
    layer.trainable = False
  x = Flatten()(vgg_19_model.output)
  prediction = Dense(2, activation='softmax')(x)  
  model = Model(inputs=vgg_19_model.input, outputs=prediction)
  return model

folds_num = 3
img_rows, img_cols = 224, 224
batch_size = 32
epoch = 10
num_of_channels = 3
number_of_class_labels = len(class_labels)

model_vgg19 = vgg_19(img_rows, img_cols, num_of_channels)
model_vgg19.compile(loss='binary_crossentropy',optimizer="adam", metrics=['accuracy'])
model_vgg19.summary()

#check that all images are moved back
move_all_labels_data_between_folders('Validation', 'Train', 1.0) 

tf.keras.utils.image_dataset_from_directory(train_path)
tf.keras.utils.image_dataset_from_directory(test_path)

# Organize file names and class labels in X and Y variables
X, Y = [], []
for i in range(len(class_labels)):
    X, Y = prepare_name_with_labels(class_labels[i], "Train", X, Y)
X = np.asarray(X)
Y = np.asarray(Y)

perf_metric_list = cross_validation_model_training(folds_num, img_rows, img_cols, 64, 30, model_vgg19)

result_df = result_presentation(perf_metric_list)
result_df

perf_result = test_results(img_rows, img_cols, batch_size, model_vgg19)

path = '/content/drive/MyDrive/IS4242 Project/models/model_vgg19.hdf5'
model_vgg19.save(path)

"""##**VGG19 - Changing number of layers to unfreeze: last 4 layers**"""

def vgg_19_trainable(img_rows, img_cols, num_of_channels):
  vgg_19_model = VGG19(input_shape=[img_rows, img_cols, num_of_channels], weights='imagenet', include_top=False)
  for layer in vgg_19_model.layers[:-2]:
    layer.trainable = False
  x = Flatten()(vgg_19_model.output)
  prediction = Dense(2, activation='softmax')(x)  
  model = Model(inputs=vgg_19_model.input, outputs=prediction)
  return model

model_vgg19_train = vgg_19_trainable(img_rows, img_cols, num_of_channels)
model_vgg19_train.compile(loss='binary_crossentropy',optimizer="adam", metrics=['accuracy'])
model_vgg19_train.summary()

for layer in model_vgg19_train.layers:
  print(layer.trainable)

# Organize file names and class labels in X and Y variables
X, Y = [], []
for i in range(len(class_labels)):
    X, Y = prepare_name_with_labels(class_labels[i], "Train", X, Y)
X = np.asarray(X)
Y = np.asarray(Y)

perf_metric_list = cross_validation_model_training(folds_num, img_rows, img_cols, 64, 30, model_vgg19_train)

perf_result = test_results(img_rows, img_cols, 64, model_vgg19_train)

"""##**VGG19 - Changing number of layers to unfreeze: last 5 layers**"""

def vgg_19_trainable1(img_rows, img_cols, num_of_channels):
  vgg_19_model = VGG19(input_shape=[img_rows, img_cols, num_of_channels], weights='imagenet', include_top=False)
  for layer in vgg_19_model.layers[:-3]:
    layer.trainable = False
  x = Flatten()(vgg_19_model.output)
  prediction = Dense(2, activation='softmax')(x)  
  model = Model(inputs=vgg_19_model.input, outputs=prediction)
  return model

model_vgg19_train1 = vgg_19_trainable1(img_rows, img_cols, num_of_channels)
model_vgg19_train1.compile(loss='binary_crossentropy',optimizer="adam", metrics=['accuracy'])
model_vgg19_train1.summary()

for layer in model_vgg19_train1.layers:
  print(layer.trainable)

# Organize file names and class labels in X and Y variables
X, Y = [], []
for i in range(len(class_labels)):
    X, Y = prepare_name_with_labels(class_labels[i], "Train", X, Y)
X = np.asarray(X)
Y = np.asarray(Y)

perf_metric_list = cross_validation_model_training(folds_num, img_rows, img_cols, 64, 30, model_vgg19_train1)

perf_result = test_results(img_rows, img_cols, 64, model_vgg19_train1)

path = '/content/drive/MyDrive/IS4242 Project/models/model_vgg19_train.hdf5'
model_vgg19_train.save(path)

path = '/content/drive/MyDrive/IS4242 Project/models/model_vgg19_train1.hdf5'
model_vgg19_train1.save(path)

"""##**INCEPTIONV3**"""

from tensorflow.keras.applications.inception_v3 import InceptionV3

def inception_v3(img_rows, img_cols, num_of_channels):
  incep_v3 = InceptionV3(input_shape=[img_rows, img_cols, num_of_channels], weights='imagenet', include_top=False)
  for layer in incep_v3.layers:
    layer.trainable = False
  x = Flatten()(incep_v3.output)
  prediction = Dense(2, activation='softmax')(x)  
  model = Model(inputs=incep_v3.input, outputs=prediction)
  
  return model

folds_num = 3
img_rows, img_cols = 224, 224
batch_size = 64
epoch = 10
num_of_channels = 3
number_of_class_labels = len(class_labels)

model_inceptionv3 = inception_v3(img_rows, img_cols, num_of_channels)
model_inceptionv3.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])
model_inceptionv3.summary()

# Organize file names and class labels in X and Y variables
X, Y = [], []
for i in range(len(class_labels)):
    X, Y = prepare_name_with_labels(class_labels[i], "Train", X, Y)
X = np.asarray(X)
Y = np.asarray(Y)

perf_metric_list = cross_validation_model_training(folds_num, img_rows, img_cols, batch_size, 20, model_inceptionv3)

result_df = result_presentation(perf_metric_list)
result_df

perf_result = test_results(img_rows, img_cols, batch_size, model_inceptionv3)

path = '/content/drive/MyDrive/IS4242 Project/models/model_incepv3.hdf5'
model_inceptionv3.save(path)

"""##**RESNET50**"""

from tensorflow.keras.applications import ResNet50

def rn50(img_rows, img_cols, num_of_channels):
  rn_50 = ResNet50(input_shape=[img_rows, img_cols, num_of_channels], weights='imagenet', include_top=False)
  for layer in rn_50.layers:
    layer.trainable = False
  x = Flatten()(rn_50.output)
  prediction = Dense(2, activation='softmax')(x)  
  model = Model(inputs=rn_50.input, outputs=prediction)
  
  return model

folds_num = 3
img_rows, img_cols = 224, 224
batch_size = 64
epoch = 10
num_of_channels = 3
number_of_class_labels = len(class_labels)

model_rn50 = rn50(img_rows, img_cols, num_of_channels)
model_rn50.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])
model_rn50.summary()

# Organize file names and class labels in X and Y variables
X, Y = [], []
for i in range(len(class_labels)):
    X, Y = prepare_name_with_labels(class_labels[i], "Train", X, Y)
X = np.asarray(X)
Y = np.asarray(Y)

perf_metric_list = cross_validation_model_training(folds_num, img_rows, img_cols, batch_size, 30, model_rn50)

result_df = result_presentation(perf_metric_list)
result_df

perf_result = test_results(img_rows, img_cols, batch_size, model_rn50)

path = '/content/drive/MyDrive/IS4242 Project/models/model_rn50.hdf5'
model_rn50.save(path)

"""## **LIME - Model Explanability**
Identify what are the features the model extract to use for prediction

## CNN
"""

img_rows, img_cols = 100, 100
batch_size = 64
epoch_num = 30
model = load_model('/content/drive/MyDrive/IS4242 Project/models/model_cnn.hdf5')

test_generator = data_augmentation_test(100, 100, 64)
predictions = model.predict(test_generator, verbose=1)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

# train_generator, validation_generator = data_augmentation_train_val(img_rows, img_cols, batch_size)
# predictions = model_vgg19_train1.predict(train_generator, verbose = 1)
# y_pred = np.argmax(predictions, axis=1)
# y_true = train_generator.classes
# indices = np.where(y_true == y_pred)[0]

TN_indices = np.where((y_true == 0) & (y_pred == 0))
TP_indices = np.where((y_true == 1) & (y_pred == 1))

# print("Indices where elements are the same:", indices)
# print("Values at those indices in a:", y_pred[indices])
# print("Values at those indices in b:", y_true[indices])

"""### True Negatives"""

idx = TN_indices[0][1]
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TN_indices[0][0]
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TN_indices[0][2]
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TN_indices[0][3]
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TN_indices[0][4]
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

"""### True Positives"""

idx = TP_indices[0][0] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][1] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][2] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][3] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][4] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][5] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][6] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][7] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][8] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][9] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][10] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][11] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][12] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=True
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][13] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][14] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][15] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][16] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][17] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=True
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][18] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][19] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][20] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][21] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][22] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][23] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][24] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][25] - 64
test_generator = data_augmentation_test(100, 100, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))



"""## VGG19"""

model_vgg19_train1 = load_model('/content/drive/MyDrive/IS4242 Project/models/model_vgg19_train1.hdf5')

test_results(224, 224, 64, model_vgg19_train1)

img_rows, img_cols = 100, 100
batch_size = 64
epoch_num = 30

test_generator = data_augmentation_test(224, 224, 64)
predictions = model_vgg19_train1.predict(test_generator, verbose=1)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

# train_generator, validation_generator = data_augmentation_train_val(img_rows, img_cols, batch_size)
# predictions = model_vgg19_train1.predict(train_generator, verbose = 1)
# y_pred = np.argmax(predictions, axis=1)
# y_true = train_generator.classes
# indices = np.where(y_true == y_pred)[0]

TN_indices = np.where((y_true == 0) & (y_pred == 0))
TP_indices = np.where((y_true == 1) & (y_pred == 1))

# print("Indices where elements are the same:", indices)
# print("Values at those indices in a:", y_pred[indices])
# print("Values at those indices in b:", y_true[indices])

"""### True Negatives"""

TN_indices[0]

idx = TN_indices[0][1]
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TN_indices[0][2]
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TN_indices[0][3]
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

"""### True Positives"""

TP_indices

idx = TP_indices[0][0] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=True
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][1] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=True
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][2] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][3] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=10,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][4] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][5] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][6] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][7] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][8] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][9] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][10] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][11] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][12] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][13] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))

idx = TP_indices[0][14] - 64
test_generator = data_augmentation_test(224, 224, 64)
img_tes = test_generator.next()
img_tes = test_generator.next()

def predict_fn(images):
    return model_vgg19_train1.predict(images)

explainer = lime_image.LimeImageExplainer(random_state=4242)
explanation = explainer.explain_instance(
         img_tes[idx].astype(float),
         predict_fn,
         top_labels=1,
         hide_color=0,
         num_samples=1000
)
image, mask = explanation.get_image_and_mask(
         explanation.top_labels[0],
         positive_only=True,
         num_features=5,
         hide_rest=False
)
plt.imshow(mark_boundaries(image, mask))



